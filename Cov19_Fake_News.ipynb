{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnWqTZXvFLXF"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEjjXWwPFJ1n"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPEmjkFGSeTS"
      },
      "source": [
        "#Check GPU Resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln1r01ElD58q"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7LhaYZdH5Jj"
      },
      "source": [
        "#Check CPU Resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Zr8tWleH5Jx"
      },
      "outputs": [],
      "source": [
        "!cat /proc/cpuinfo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/meminfo"
      ],
      "metadata": {
        "id": "iBWa6efDIRrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWvCnTrdSi_l"
      },
      "source": [
        "#Install AutoTime to Measure the runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUrmcp6xDGz7"
      },
      "outputs": [],
      "source": [
        "!pip install ipython-autotime hypopt\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vACev8lTNHh9"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgmUs8-M9dPf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV, KFold, cross_val_score, RandomizedSearchCV\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, SVMSMOTE, BorderlineSMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "from joblib import dump, load\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn import tree\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFERcI4RSryZ"
      },
      "source": [
        "# Common Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLNAdRkzC-EV"
      },
      "source": [
        "## Plot The Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SIIlryV9jso"
      },
      "outputs": [],
      "source": [
        "## https://github.com/parthpatwa/covid19-fake-news-detection/blob/main/ml_baseline-test.ipynb\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    #plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqJl2naC9xwB"
      },
      "outputs": [],
      "source": [
        "stops = set(stopwords.words(\"english\"))\n",
        "def cleantext(string):\n",
        "    text = string.lower().split()\n",
        "    text = \" \".join(text)\n",
        "    text = re.sub(r\"http(\\S)+\",' ',text)\n",
        "    text = re.sub(r\"www(\\S)+\",' ',text)\n",
        "    text = re.sub(r\"&\",' and ',text)\n",
        "    tx = text.replace('&amp',' ')\n",
        "    text = re.sub(r\"[^0-9a-zA-Z]+\",' ',text)\n",
        "    text = text.split()\n",
        "    text = [w for w in text if not w in stops]\n",
        "    text = \" \".join(text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKKR9S-uNQGw"
      },
      "source": [
        "# Import Dataset and Define the Random State"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnez5i7z-BEw"
      },
      "outputs": [],
      "source": [
        "# Dataset can be obtained from\n",
        "\n",
        "PATH = '/content/drive/MyDrive/UNS/dataset/'\n",
        "train = pd.read_csv(PATH + 'Constraint_Train.csv')\n",
        "val = pd.read_csv(PATH + 'Constraint_Val.csv')\n",
        "test = pd.read_csv(PATH + 'english_test_with_labels.csv')\n",
        "\n",
        "RANDOM_STATE = 21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LH5xA8LW-FtQ"
      },
      "outputs": [],
      "source": [
        "train['tweet'] = train['tweet'].map(lambda x: cleantext(x))\n",
        "train ['label'] = train['label'].map(lambda x: cleantext(x))\n",
        "val['tweet'] = val['tweet'].map(lambda x: cleantext(x))\n",
        "val['label'] = val['label'].map(lambda x: cleantext(x))\n",
        "test['tweet'] = test['tweet'].map(lambda x: cleantext(x))\n",
        "test ['label'] = test['label'].map(lambda x: cleantext(x))\n",
        "new_train = train['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sM_4hD9YSTe3"
      },
      "outputs": [],
      "source": [
        "print(train['label'])\n",
        "print(train['tweet'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx4NpaodSVMX"
      },
      "outputs": [],
      "source": [
        "labels = []\n",
        "for name in train['label'].values:\n",
        "    #print (name)\n",
        "    #temp = r[\"Label\"]\n",
        "    if  name == \"fake\" :\n",
        "        labels.append(0)\n",
        "    elif name == \"real\" :\n",
        "        labels.append(1)\n",
        "new_train_label = labels\n",
        "#print (len(labels[labels == 1]))\n",
        "a = np.where(np.array(labels) == 1)\n",
        "b = np.array(labels)\n",
        "c = b[b==1]\n",
        "d = b[b==0]\n",
        "#print (a)\n",
        "#print (labels[a])\n",
        "#len(labels)\n",
        "print (len(c))\n",
        "print (len(d))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCQH0zXNcU38"
      },
      "outputs": [],
      "source": [
        "a= train['label'].value_counts()\n",
        "a_species = a.index\n",
        "a_count = a.values\n",
        "\n",
        "b= val['label'].value_counts()\n",
        "b_species = b.index\n",
        "b_count = b.values\n",
        "\n",
        "c= test['label'].value_counts()\n",
        "c_species = c.index\n",
        "c_count = c.values\n",
        "\n",
        "# set width of bar\n",
        "barWidth = 0.25\n",
        "fig = plt.subplots(figsize =(12, 8))\n",
        "\n",
        "# Set position of bar on X axis\n",
        "br1 = np.arange(len(a_count))\n",
        "br2 = [x + barWidth for x in br1]\n",
        "br3 = [x + barWidth for x in br2]\n",
        "\n",
        "# Make the plot\n",
        "plt.bar(br1, a_count/100, fill=False, width = barWidth,\n",
        "        edgecolor ='grey', hatch='x', label='Training Data')\n",
        "plt.bar(br2, b_count/100, fill=False, width = barWidth,\n",
        "        edgecolor ='grey', hatch='+', label='Validation Data')\n",
        "plt.bar(br3, c_count/100, fill=False, width = barWidth,\n",
        "        edgecolor ='grey', hatch='o', label='Testing Data')\n",
        "\n",
        "# Adding Xticks\n",
        "plt.xlabel('Social Media News', fontsize = 16)\n",
        "plt.ylabel('Count (x 100)', fontsize = 16)\n",
        "plt.xticks([r + barWidth for r in range(len(a_count))],\n",
        "        ['Real', 'Fake'], fontsize = 14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.title('Dataset Composition', fontweight ='bold', fontsize=20)\n",
        "\n",
        "plt.legend(fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFF70vRkOF-6"
      },
      "source": [
        "##**Define Metrices**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy_fbI5d-Vyg"
      },
      "outputs": [],
      "source": [
        "def print_metrices(pred,true):\n",
        "    accuracy = accuracy_score(pred,true)\n",
        "    precision = precision_score(pred, true, average = 'weighted')\n",
        "    recall = recall_score(pred,true, average = 'weighted')\n",
        "    f1 = f1_score(pred, true, average = 'weighted')\n",
        "    print(\"Accuracy : \",accuracy)\n",
        "    print(\"Precison : \",precision)\n",
        "    print(\"Recall : \",recall)\n",
        "    print(\"F1 : \",f1)\n",
        "    return accuracy, precision, recall, f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdwVBVAiSxoN"
      },
      "source": [
        "# Original Baseline for Training, Validation, and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZUmtOdxZbyD"
      },
      "source": [
        "## Method for Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOWTwnnwZlGK"
      },
      "outputs": [],
      "source": [
        "# This method is adapted from the original source-code on:\n",
        "# https://github.com/parthpatwa/covid19-fake-news-detection/blob/main/ml_baseline.ipynb\n",
        "def train_val_baseline(pipeline, method_title):\n",
        "  print(f'Training and Validation of {method_title}')\n",
        "\n",
        "  # get the starting time\n",
        "  t0 = time()\n",
        "\n",
        "  # fit the model with the data\n",
        "  fit = pipeline.fit(train['tweet'],train['label'])\n",
        "\n",
        "  pred=pipeline.predict(val['tweet'])\n",
        "  print(f'Time: {time() - t0} \\nPerformance score:')\n",
        "\n",
        "  # display the elapsed time and performance scores\n",
        "  print_metrices(pred, val['label'])\n",
        "  plot_confusion_matrix(confusion_matrix(val['label'], pred),\n",
        "                        target_names=['fake','real'],\n",
        "                        normalize = False,\n",
        "                        title = f'Confusion matix of {method_title} on val data')\n",
        "\n",
        "  val_ori = pd.read_csv(PATH + 'Constraint_Val.csv')\n",
        "  val_misclass_df = val_ori[pred!=val['label']]\n",
        "  val_misclass_df.info()\n",
        "  val_misclass_df.to_csv(PATH + f'{method_title}_val_misclassified.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5LTPBpNjVO8"
      },
      "source": [
        "## Method for Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfL44nMIjVPI"
      },
      "outputs": [],
      "source": [
        "# This method is adapted from the original source-code on:\n",
        "# https://github.com/parthpatwa/covid19-fake-news-detection/blob/main/ml_baseline-test.ipynb\n",
        "def test_baseline(pipeline, method_title):\n",
        "  print(f'Testing Baseline of {method_title}')\n",
        "\n",
        "  # get the starting time\n",
        "  t0 = time()\n",
        "\n",
        "  # fit the model with the data\n",
        "  fit = pipeline.fit(train['tweet'],train['label'])\n",
        "\n",
        "  pred=pipeline.predict(test['tweet'])\n",
        "\n",
        "  # display the elapsed time and performance scores\n",
        "  print(f'Time: {time() - t0} \\nPerformance score:')\n",
        "\n",
        "  print_metrices(pred, test['label'])\n",
        "  plot_confusion_matrix(confusion_matrix(val['label'], pred),\n",
        "                        target_names=['fake','real'],\n",
        "                        normalize = False,\n",
        "                        title = f'Confusion matix of {method_title} on Test data')\n",
        "\n",
        "  test_ori = pd.read_csv(PATH + 'Constraint_Test.csv')\n",
        "  test_misclass_df = test_ori[pred!=test['label']]\n",
        "  test_misclass_df.info()\n",
        "  test_misclass_df.to_csv(PATH + f'{method_title}_test_misclassified.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8OTQYCn4SUI"
      },
      "source": [
        "## Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0TofCtv2C4u"
      },
      "outputs": [],
      "source": [
        "#minor variations in final results due to randomness\n",
        "pipeline = Pipeline([\n",
        "        ('bow', CountVectorizer()),\n",
        "        ('tfidf', TfidfTransformer()),\n",
        "        ('c', GradientBoostingClassifier())\n",
        "    ])\n",
        "\n",
        "train_val_baseline(pipeline, 'GDBT')\n",
        "print('\\n\\n')\n",
        "test_baseline(pipeline, 'GDBT')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EilJMt084VbP"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5Q1satfThlT"
      },
      "outputs": [],
      "source": [
        "#minor variations in final results due to randomness\n",
        "pipeline = Pipeline([\n",
        "        ('bow', CountVectorizer()),\n",
        "        ('tfidf', TfidfTransformer()),\n",
        "        ('c', tree.DecisionTreeClassifier())\n",
        "    ])\n",
        "\n",
        "train_val_baseline(pipeline, 'DT')\n",
        "print('\\n\\n')\n",
        "test_baseline(pipeline, 'DT')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PivIXL4TeH5n"
      },
      "source": [
        "## Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oq6ScO62eH5o"
      },
      "outputs": [],
      "source": [
        "#minor variations in final results due to randomness\n",
        "pipeline = Pipeline([\n",
        "        ('bow', CountVectorizer()),\n",
        "        ('tfidf', TfidfTransformer()),\n",
        "        ('c', MultinomialNB(alpha=0.1))\n",
        "    ])\n",
        "\n",
        "train_val_baseline(pipeline, 'MNB')\n",
        "print('\\n\\n')\n",
        "test_baseline(pipeline, 'MNB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Le-bFb_ieiyL"
      },
      "source": [
        "## Complement Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6Jg1pIieiyg"
      },
      "outputs": [],
      "source": [
        "#minor variations in final results due to randomness\n",
        "pipeline = Pipeline([\n",
        "        ('bow', CountVectorizer()),\n",
        "        ('tfidf', TfidfTransformer()),\n",
        "        ('c', ComplementNB(alpha=0.1))\n",
        "    ])\n",
        "\n",
        "train_val_baseline(pipeline, 'MNC')\n",
        "print('\\n\\n')\n",
        "test_baseline(pipeline, 'MNC')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PySTcnduYqS"
      },
      "source": [
        "#Choosing the Right Hyperparameter for Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aywClJ7Z51Wf"
      },
      "source": [
        "## Use Hyperparameter Searching Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSTQqYcp4BHt"
      },
      "outputs": [],
      "source": [
        "def hyper_param_search(pipeline, parameter, file_name, cv_range = range(5,11)):\n",
        "  performance_array = []\n",
        "  # Perform the grid search\n",
        "  for i in cv_range:\n",
        "      grid_search = GridSearchCV(pipeline, parameters, cv=i, n_jobs=2, verbose=1)\n",
        "      t0 = time()\n",
        "      grid_search.fit(train['tweet'], train['label'])\n",
        "      gs_time = time() - t0\n",
        "\n",
        "      # Display the best parameters, its testing score, and validation score\n",
        "      gs_best_param = grid_search.best_params_\n",
        "      gs_best_score = grid_search.best_score_\n",
        "      gs_val_score = grid_search.score(val['tweet'], val['label'])\n",
        "\n",
        "      # Print the best parameters and score for each cross-validation value\n",
        "      print(\"Cross-validation value: \", i)\n",
        "      print(\"Best parameters: \", gs_best_param)\n",
        "      print(\"Best Train score: \", gs_best_score)\n",
        "      print('Validation Score:', gs_val_score)\n",
        "      print('Runtime:', gs_time)\n",
        "\n",
        "      # Populate the parameters, scores, and running time for later table\n",
        "      performance_array.append([i, gs_best_param,\n",
        "                                gs_best_score,\n",
        "                                gs_val_score,\n",
        "                                gs_time])\n",
        "\n",
        "  # convert the previously collected performance array into Panda DataFrame\n",
        "  # and arrange the columns\n",
        "  data_df = pd.DataFrame(performance_array, columns=['k', 'best_param',\n",
        "                                                     'best_score', 'val_score',\n",
        "                                                     'time'])\n",
        "\n",
        "  # Write the DataFrame to a CSV file\n",
        "  data_df.to_csv(PATH + file_name, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yigvoSWgvjk6"
      },
      "source": [
        "##GradientBoosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN5MTVc244tc"
      },
      "source": [
        "###Without SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Finding the best parameters"
      ],
      "metadata": {
        "id": "-2xIlGv4PMC5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvIPfC2O44tl"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('gb', GradientBoostingClassifier(random_state=RANDOM_STATE))\n",
        "])\n",
        "\n",
        "# Define the parameters to be tuned\n",
        "parameters = {\n",
        "    'gb__n_estimators': [750, 1000, 1500],\n",
        "    'gb__learning_rate': [1.0, 0.1, 0.01],\n",
        "    'gb__subsample': np.arange(0.5, 1.1, 0.1).tolist()\n",
        "}\n",
        "\n",
        "# Perform hyperparameter search\n",
        "hyper_param_search(pipeline, parameters, 'GB_HYPERPARAM.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmtm7dEr-YQM"
      },
      "source": [
        "####Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMOgzPXz-YQ4"
      },
      "outputs": [],
      "source": [
        "#minor variations in final results due to randomness\n",
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('gb', GradientBoostingClassifier(random_state=RANDOM_STATE,\n",
        "                                      learning_rate=0.1, n_estimators=1500,\n",
        "                                      subsample=0.7999999999999999))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Validation"
      ],
      "metadata": {
        "id": "RPSxlFfJKfV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_baseline(pipeline, 'GB with Hyperparameter Tuned')\n"
      ],
      "metadata": {
        "id": "0UcUBdb-KVhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing"
      ],
      "metadata": {
        "id": "9CkrMJgvKp8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_baseline(pipeline, 'GB with Hyperparameter Tuned')"
      ],
      "metadata": {
        "id": "3zX1K4lDKt0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWw2XEO54zci"
      },
      "source": [
        "###With SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Finding the best parameters"
      ],
      "metadata": {
        "id": "MZsv6AR0PWVr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7P5XqtAvm0A"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('sampling', SMOTE(random_state=RANDOM_STATE,\n",
        "                       sampling_strategy='minority',\n",
        "                       n_jobs=-1)),\n",
        "    ('gb', GradientBoostingClassifier(random_state=RANDOM_STATE,\n",
        "                                      learning_rate=0.1, n_estimators=1500,\n",
        "                                      subsample=0.7999999999999999))\n",
        "])\n",
        "\n",
        "# Define the parameters to be tuned\n",
        "parameters = {\n",
        "    'sampling__sampling_strategy': ['minority', 'not minority', 'all'],\n",
        "    'sampling__k_neighbors': np.arange(1, 101).tolist()\n",
        "}\n",
        "\n",
        "# Perform hyperparameter search\n",
        "hyper_param_search(pipeline, parameters, 'GB_SMOTE_HYPERPARAM.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo4cRU9cA1qG"
      },
      "source": [
        "####Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtxkvPIQA1qH"
      },
      "outputs": [],
      "source": [
        "#minor variations in final results due to randomness\n",
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('sampling', SMOTE(random_state=RANDOM_STATE,\n",
        "                       sampling_strategy='minority',\n",
        "                       k_neighbors=2)),\n",
        "    ('gb', GradientBoostingClassifier(random_state=RANDOM_STATE,\n",
        "                                      learning_rate=0.1, n_estimators=1500,\n",
        "                                      subsample=0.7999999999999999))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Validation"
      ],
      "metadata": {
        "id": "V79Ky4bpJabO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_baseline(pipeline, 'GB and SMOTE (k=2) with Hyperparameter Tuned')"
      ],
      "metadata": {
        "id": "3vgNnoZHJAC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Testing"
      ],
      "metadata": {
        "id": "3lNe4JtAJlCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_baseline(pipeline, 'GB and SMOTE (k=2) with Hyperparameter Tuned')"
      ],
      "metadata": {
        "id": "cdYzepl7JEsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt_9bXsZxSxq"
      },
      "source": [
        "##Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC8KC-LxZCNv"
      },
      "source": [
        "###Without SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Finding the best parameters"
      ],
      "metadata": {
        "id": "m00_uFlgPi30"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQBsT7ZOZCN6"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('dt', tree.DecisionTreeClassifier(random_state=RANDOM_STATE))\n",
        "])\n",
        "\n",
        "# Define the parameters to be tuned\n",
        "parameters = {\n",
        "    'dt__min_samples_split': np.arange(2, 21, 2).tolist(),\n",
        "    'dt__class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "# Perform hyperparameter search\n",
        "hyper_param_search(pipeline, parameters, 'DT_HYPERPARAM.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUMQvnVvDSMc"
      },
      "source": [
        "####Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZTXpfVsDSM-"
      },
      "outputs": [],
      "source": [
        "# Random State to ensure a reproduceable result\n",
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('dt', tree.DecisionTreeClassifier(random_state=RANDOM_STATE,\n",
        "                                       class_weight=None,\n",
        "                                       min_samples_split=16))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Validation"
      ],
      "metadata": {
        "id": "aAMmBipRMrrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_baseline(pipeline, 'DT with Hyperparameter Tuned')\n"
      ],
      "metadata": {
        "id": "HjidEgELMrrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing"
      ],
      "metadata": {
        "id": "9tNrVcDUMrrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_baseline(pipeline, 'DT with Hyperparameter Tuned')"
      ],
      "metadata": {
        "id": "H0KgWw84Mrrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8W3N4OdY8-4"
      },
      "source": [
        "###With SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Finding the best parameters"
      ],
      "metadata": {
        "id": "XjR3BU-cQeMn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFbtcX-ExWcC"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('sampling', SMOTE(random_state=RANDOM_STATE, n_jobs=-1)),\n",
        "    ('dt', tree.DecisionTreeClassifier(random_state=RANDOM_STATE,\n",
        "                                       min_samples_split=16,\n",
        "                                       class_weight=None))\n",
        "])\n",
        "\n",
        "# Define the parameters to be tuned\n",
        "parameters = {\n",
        "    'sampling__sampling_strategy': ['minority', 'not minority', 'all'],\n",
        "    'sampling__k_neighbors': np.arange(1, 101).tolist()\n",
        "}\n",
        "\n",
        "# Perform hyperparameter search\n",
        "hyper_param_search(pipeline, parameters, 'DT_SMOTE_HYPERPARAM.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uTx6aITGrKB"
      },
      "source": [
        "####Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-26AFGP-GrKR"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('sampling', SMOTE(random_state=RANDOM_STATE,\n",
        "                       k_neighbors=29,\n",
        "                       sampling_strategy='minority')),\n",
        "    ('dt', tree.DecisionTreeClassifier(random_state=RANDOM_STATE,\n",
        "                                       class_weight=None,\n",
        "                                       min_samples_split=16))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Validation"
      ],
      "metadata": {
        "id": "fDxriWW5M5-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_baseline(pipeline, 'DT and SMOTE (k=29) with Hyperparameter Tuned')\n"
      ],
      "metadata": {
        "id": "edrqqaoBM5_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing"
      ],
      "metadata": {
        "id": "ZxSQN0MBM5_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_baseline(pipeline, 'DT and SMOTE (k=29) with Hyperparameter Tuned')"
      ],
      "metadata": {
        "id": "aqn_O5ZEM5_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unvDMMYmuw0g"
      },
      "source": [
        "##Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzy67awX3nKV"
      },
      "source": [
        "###Without SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Finding the best parameters"
      ],
      "metadata": {
        "id": "LQvRXbycQjo6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkEturVhUcfP"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('mnb', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Define the parameters to be tuned\n",
        "parameters = {\n",
        "    'mnb__alpha': [100, 10, 1.0, 0.1, 0.01]#,\n",
        "}\n",
        "\n",
        "# Perform hyperparameter search\n",
        "hyper_param_search(pipeline, parameters, 'MNB_HYPERPARAM.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jHdWcrJzNXt"
      },
      "source": [
        "####Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4MuYF-VYP8X"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('mnb', MultinomialNB(alpha=0.1))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Validation"
      ],
      "metadata": {
        "id": "Xdj5sBEyNH-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_baseline(pipeline, 'MNB with Hyperparameter Tuned')\n"
      ],
      "metadata": {
        "id": "V3WNGJToNH-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing"
      ],
      "metadata": {
        "id": "8JRROrGKNH-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_baseline(pipeline, 'MNB with Hyperparameter Tuned')"
      ],
      "metadata": {
        "id": "wsggXV26NH-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2czCZuX387c"
      },
      "source": [
        "###With SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Finding the best parameters"
      ],
      "metadata": {
        "id": "6862_Hl2QtYr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GbcVAQ6387c"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('sampling', SMOTE(random_state=RANDOM_STATE, n_jobs=-1)),\n",
        "    ('mnb', MultinomialNB(alpha=0.1))\n",
        "])\n",
        "\n",
        "# Define the parameters to be tuned\n",
        "parameters = {\n",
        "    'sampling__sampling_strategy': ['minority', 'not minority', 'all'],\n",
        "    'sampling__k_neighbors': np.arange(1, 101).tolist()\n",
        "}\n",
        "\n",
        "# Perform hyperparameter search\n",
        "hyper_param_search(pipeline, parameters, 'MNB_SMOTE_HYPERPARAM.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjLcctakzxAz"
      },
      "source": [
        "####Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9gPiNOga7-U"
      },
      "outputs": [],
      "source": [
        "#minor variations in final results due to randomness\n",
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('sampling', SMOTE(random_state=RANDOM_STATE,\n",
        "                       k_neighbors=45,\n",
        "                       sampling_strategy='minority')),\n",
        "    ('mnb', MultinomialNB(alpha=0.1))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Validation"
      ],
      "metadata": {
        "id": "pz7Lsr01NVTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_baseline(pipeline, 'MNB and SMOTE (k=45) with Hyperparameter Tuned')\n"
      ],
      "metadata": {
        "id": "uAhcjMlJNVTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing"
      ],
      "metadata": {
        "id": "PZj58fQZNVTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_baseline(pipeline, 'MNB and SMOTE (k=45) with Hyperparameter Tuned')"
      ],
      "metadata": {
        "id": "I_aiDQbUNVTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bQV7G5-4z9e"
      },
      "source": [
        "##Complement Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WilojFCJ4LWl"
      },
      "source": [
        "###Without SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Finding the best parameters"
      ],
      "metadata": {
        "id": "eR-UOpckQ3rR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cmp7S5374LWu"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('mnc', ComplementNB())\n",
        "])\n",
        "\n",
        "# Define the parameters to be tuned\n",
        "parameters = {\n",
        "    'mnc__norm': [True, False],\n",
        "    'mnc__alpha': [100, 10, 1.0, 0.1, 0.01]\n",
        "}\n",
        "\n",
        "# Perform hyperparameter search\n",
        "hyper_param_search(pipeline, parameters, 'MNC_HYPERPARAM.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ_pyqnNz-28"
      },
      "source": [
        "####Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJcpiQ7Vb-lR"
      },
      "outputs": [],
      "source": [
        "#minor variations in final results due to randomness\n",
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('mnc', ComplementNB(alpha=0.1))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Validation"
      ],
      "metadata": {
        "id": "p1IVSovMNenR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_baseline(pipeline, 'MNC Hyperparameter Tuned')\n"
      ],
      "metadata": {
        "id": "01Si3kyINenp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing"
      ],
      "metadata": {
        "id": "ceAH0WoTNenq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_baseline(pipeline, 'MNC Hyperparameter Tuned')"
      ],
      "metadata": {
        "id": "cAAUKq7qNenr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpPqKql94HiK"
      },
      "source": [
        "###With SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Finding the best parameters"
      ],
      "metadata": {
        "id": "y9nCa4BfRCHO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I24Ff0on42o6"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('sampling', SMOTE(random_state=RANDOM_STATE, n_jobs=-1)),\n",
        "    ('mnc', ComplementNB(alpha=0.1))\n",
        "])\n",
        "\n",
        "# Define the parameters to be tuned\n",
        "parameters = {\n",
        "    'sampling__sampling_strategy': ['minority', 'not minority', 'all'],\n",
        "    'sampling__k_neighbors': np.arange(1, 101).tolist()\n",
        "}\n",
        "\n",
        "# Perform hyperparameter search\n",
        "hyper_param_search(pipeline, parameters, 'MNC_SMOTE_HYPERPARAM.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7oOQxLz0EgY"
      },
      "source": [
        "####Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNOwqyyXc07O"
      },
      "outputs": [],
      "source": [
        "#minor variations in final results due to randomness\n",
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('sampling', SMOTE(random_state=RANDOM_STATE, k_neighbors=45,\n",
        "                       sampling_strategy='minority')),\n",
        "    ('mnc', ComplementNB(alpha=0.1))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Validation"
      ],
      "metadata": {
        "id": "TbkVYiDWNr3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_baseline(pipeline, 'MNC and SMOTE (k=45) Hyperparameter Tuned')\n"
      ],
      "metadata": {
        "id": "lOHRpdeKNr39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing"
      ],
      "metadata": {
        "id": "CUTM4juoNr39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_baseline(pipeline, 'MNC and SMOTE (k=45) Hyperparameter Tuned')"
      ],
      "metadata": {
        "id": "La_aqnESNr3-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}